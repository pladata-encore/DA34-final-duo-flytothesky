{"cells":[{"cell_type":"code","source":["%mv bark-voice-cloning-HuBERT-quantizer/* *\n","%rm -rf bark-voice-cloning-HuBERT-quantizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OE0PFtvq4bp","executionInfo":{"status":"ok","timestamp":1720484856206,"user_tz":-540,"elapsed":436,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"429046ed-b95f-4644-f3f1-670823050d0d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot stat 'bark-voice-cloning-HuBERT-quantizer/*': No such file or directory\n"]}]},{"cell_type":"code","source":["%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"pFMNikbAq5Kq","executionInfo":{"status":"ok","timestamp":1720484938136,"user_tz":-540,"elapsed":81331,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"3518542e-365b-4131-cba6-ae18e06a6133"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu117\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu117)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Collecting torch\n","  Using cached https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp310-cp310-linux_x86_64.whl (1843.9 MB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Collecting triton==2.0.0 (from torch)\n","  Using cached https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.9)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (15.0.7)\n","INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchaudio\n","  Using cached https://download.pytorch.org/whl/cu117/torchaudio-2.0.2%2Bcu117-cp310-cp310-linux_x86_64.whl (4.4 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: triton, torch, torchaudio\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.1\n","    Uninstalling triton-2.3.1:\n","      Successfully uninstalled triton-2.3.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.1\n","    Uninstalling torch-2.3.1:\n","      Successfully uninstalled torch-2.3.1\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.3.1\n","    Uninstalling torchaudio-2.3.1:\n","      Successfully uninstalled torchaudio-2.3.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","audiolm-pytorch 2.0.7 requires torch>=2.1, but you have torch 2.0.1+cu117 which is incompatible.\n","gateloop-transformer 0.2.5 requires torch>=2.1, but you have torch 2.0.1+cu117 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1+cu117 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.0.1+cu117 torchaudio-2.0.2+cu117 triton-2.0.0\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/serp-ai/bark-with-voice-clone\n","%cd bark-with-voice-clone/\n","%pip install git+https://github.com/suno-ai/bark.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1KOEOxUSq58f","executionInfo":{"status":"ok","timestamp":1720484953641,"user_tz":-540,"elapsed":15516,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"2a34776a-c4ae-48a3-abd0-b484b7b7adf2","collapsed":true},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'bark-with-voice-clone'...\n","remote: Enumerating objects: 559, done.\u001b[K\n","remote: Counting objects: 100% (176/176), done.\u001b[K\n","remote: Compressing objects: 100% (39/39), done.\u001b[K\n","remote: Total 559 (delta 147), reused 137 (delta 137), pack-reused 383\u001b[K\n","Receiving objects: 100% (559/559), 1.43 MiB | 3.88 MiB/s, done.\n","Resolving deltas: 100% (248/248), done.\n","/content/bark-with-voice-clone\n","Collecting git+https://github.com/suno-ai/bark.git\n","  Cloning https://github.com/suno-ai/bark.git to /tmp/pip-req-build-rixgix7e\n","  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git /tmp/pip-req-build-rixgix7e\n","  Resolved https://github.com/suno-ai/bark.git to commit f4f32d4cd480dfec1c245d258174bc9bde3c2148\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.34.141)\n","Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (0.1.1)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (2.0)\n","Requirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (0.23.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.11.4)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (0.19.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (2.0.1+cu117)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.66.4)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.12.2)\n","Requirement already satisfied: botocore<1.35.0,>=1.34.141 in /usr/local/lib/python3.10/dist-packages (from boto3->suno-bark==0.0.1a0) (1.34.141)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->suno-bark==0.0.1a0) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->suno-bark==0.0.1a0) (0.10.2)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec->suno-bark==0.0.1a0) (2.0.2+cu117)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from encodec->suno-bark==0.0.1a0) (0.8.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.4)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->suno-bark==0.0.1a0) (3.27.9)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->suno-bark==0.0.1a0) (15.0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (0.4.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.141->boto3->suno-bark==0.0.1a0) (2.8.2)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.141->boto3->suno-bark==0.0.1a0) (2.0.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->suno-bark==0.0.1a0) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.141->boto3->suno-bark==0.0.1a0) (1.16.0)\n"]}]},{"cell_type":"code","source":["from bark.generation import load_codec_model, generate_text_semantic\n","from encodec.utils import convert_audio\n","\n","import torchaudio\n","import torch\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = load_codec_model(use_gpu=True if device == 'cuda' else False)"],"metadata":{"id":"jsA429xuq6CY","executionInfo":{"status":"ok","timestamp":1720484958891,"user_tz":-540,"elapsed":5275,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('./hubert')\n"],"metadata":{"id":"J2HLG-o6q-U_","executionInfo":{"status":"ok","timestamp":1720484958891,"user_tz":-540,"elapsed":16,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('./bark-voice-cloning-HuBERT-quantizer')\n","import os\n","from scipy.io.wavfile import write as write_wav\n","import numpy as np\n","import torch\n","import torchaudio\n","from bark.api import generate_audio\n","from bark.generation import SAMPLE_RATE, preload_models, load_codec_model\n","from encodec.utils import convert_audio\n","from hubert.customtokenizer import CustomTokenizer\n","from hubert.hubert_manager import HuBERTManager\n","from hubert.pre_kmeans_hubert import CustomHubert"],"metadata":{"id":"nPdK4utdq_xu","executionInfo":{"status":"ok","timestamp":1720484963515,"user_tz":-540,"elapsed":4639,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"kcsmkIdsqIjN","executionInfo":{"status":"ok","timestamp":1720484963516,"user_tz":-540,"elapsed":5,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["from bark.generation import load_codec_model, generate_text_semantic\n","from encodec.utils import convert_audio\n","\n","import torchaudio\n","import torch\n","\n","device = 'cuda' # or 'cpu'\n","model = load_codec_model(use_gpu=True if device == 'cuda' else False)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XWMxohekqIjQ","colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["2de9c7790b39443d9720ca7ba35740bf","25ae0a1132164cd3945f61ba297625fb","955bfcf0413749afb3e64d58485f5898","448b449c1f9f45ebb8ef1bb394025566","e1e523696c4c473d9d6a52fba23b831c","ff468b00ed6a40898d12adbac51ff16e","8900dfe65f1f4394a6954fb2e450eda5","327c26a9111e4d63819fd270219a17a4","2fcac51c0f324b3b88a73ed13bf80192","5d015b7d0a0a406f8283b90de842f1cb","c1f605d8490b46f3be562844b96f1f8d"]},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1720484973709,"user_tz":-540,"elapsed":10197,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"9d0cd767-9fb9-4af3-b160-f124bf856257"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading HuBERT base model\n","Downloaded HuBERT\n","Downloading HuBERT custom tokenizer\n"]},{"output_type":"display_data","data":{"text/plain":["quantifier_hubert_base_ls960_14.pth:   0%|          | 0.00/104M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de9c7790b39443d9720ca7ba35740bf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloaded tokenizer\n"]},{"output_type":"execute_result","data":{"text/plain":["'data/models/hubert/tokenizer.pth'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n","from hubert.hubert_manager import HuBERTManager\n","hubert_manager = HuBERTManager()\n","hubert_manager.make_sure_hubert_installed()\n","hubert_manager.make_sure_tokenizer_installed()"]},{"cell_type":"code","source":["!pip install --upgrade torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"qxGVtkrx4RKB","executionInfo":{"status":"ok","timestamp":1720484711968,"user_tz":-540,"elapsed":5990,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"687ea127-8774-4ff9-b309-1a166ff1d3ce"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install fairseq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"zvqzR63CsEy1","executionInfo":{"status":"ok","timestamp":1720484522308,"user_tz":-540,"elapsed":48167,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"d940eed1-df25-4bf8-b15d-ed9bc85c10df"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fairseq\n","  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.10)\n","Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2024.5.15)\n","Collecting sacrebleu>=1.4.12 (from fairseq)\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu117)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.4)\n","Collecting bitarray (from fairseq)\n","  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu117)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.25.2)\n","Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.12.2)\n","Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n","  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n","Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.4)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.27.9)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (15.0.7)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n","Building wheels for collected packages: fairseq, antlr4-python3-runtime\n","  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11289145 sha256=ef4b12797d3ed0a209a95fce56b7f2fe17f0e76417109977d2dc0af6abd8a2f8\n","  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=c46694f01c50066e7d4a1675a24626014656c2d84b2f6f3b69fc334c84b73cdb\n","  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n","Successfully built fairseq antlr4-python3-runtime\n","Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.10.0 sacrebleu-2.4.2\n"]}]},{"cell_type":"code","source":["!pip install audiolm_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"hT3Yo01n3rCd","executionInfo":{"status":"ok","timestamp":1720484651622,"user_tz":-540,"elapsed":104331,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"fcde3a6d-5956-4999-f2ca-58ee9417ec01"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting audiolm_pytorch\n","  Downloading audiolm_pytorch-2.0.7-py3-none-any.whl (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate>=0.24.0 (from audiolm_pytorch)\n","  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype>=0.16.1 (from audiolm_pytorch)\n","  Downloading beartype-0.18.5-py3-none-any.whl (917 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (0.8.0)\n","Collecting ema-pytorch>=0.2.2 (from audiolm_pytorch)\n","  Downloading ema_pytorch-0.5.1-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (0.1.1)\n","Requirement already satisfied: fairseq in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (0.12.2)\n","Collecting wandb (from audiolm_pytorch)\n","  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gateloop-transformer>=0.2.3 (from audiolm_pytorch)\n","  Downloading gateloop_transformer-0.2.5-py3-none-any.whl (10 kB)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (1.4.2)\n","Collecting local-attention>=1.9.0 (from audiolm_pytorch)\n","  Downloading local_attention-1.9.14-py3-none-any.whl (9.0 kB)\n","Collecting pytorch-warmup (from audiolm_pytorch)\n","  Downloading pytorch_warmup-0.1.1-py3-none-any.whl (6.6 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (1.2.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (0.1.99)\n","Collecting torch>=2.1 (from audiolm_pytorch)\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (2.0.2+cu117)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (4.41.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audiolm_pytorch) (4.66.4)\n","Collecting vector-quantize-pytorch>=1.12.5 (from audiolm_pytorch)\n","  Downloading vector_quantize_pytorch-1.15.1-py3-none-any.whl (38 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm_pytorch) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm_pytorch) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm_pytorch) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm_pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm_pytorch) (0.23.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.24.0->audiolm_pytorch) (0.4.3)\n","Collecting rotary-embedding-torch (from gateloop-transformer>=0.2.3->audiolm_pytorch)\n","  Downloading rotary_embedding_torch-0.6.4-py3-none-any.whl (5.4 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm_pytorch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm_pytorch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm_pytorch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm_pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm_pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->audiolm_pytorch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1->audiolm_pytorch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting triton==2.3.1 (from torch>=2.1->audiolm_pytorch)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->audiolm_pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einx>=0.2.2 (from vector-quantize-pytorch>=1.12.5->audiolm_pytorch)\n","  Downloading einx-0.3.0-py3-none-any.whl (102 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm_pytorch) (1.16.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm_pytorch) (3.0.10)\n","Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm_pytorch) (1.0.7)\n","Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm_pytorch) (2.0.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm_pytorch) (2024.5.15)\n","Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm_pytorch) (2.4.2)\n","Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from fairseq->audiolm_pytorch) (2.9.2)\n","INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchaudio (from audiolm_pytorch)\n","  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm_pytorch) (1.11.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm_pytorch) (3.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->audiolm_pytorch) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->audiolm_pytorch) (0.19.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm_pytorch) (8.1.7)\n","Collecting docker-pycreds>=0.4.0 (from wandb->audiolm_pytorch)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->audiolm_pytorch)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm_pytorch) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm_pytorch) (3.20.3)\n","Collecting sentry-sdk>=1.0.0 (from wandb->audiolm_pytorch)\n","  Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setproctitle (from wandb->audiolm_pytorch)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->audiolm_pytorch) (67.7.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->audiolm_pytorch) (1.16.0)\n","Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from einx>=0.2.2->vector-quantize-pytorch>=1.12.5->audiolm_pytorch) (2.4.4)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->audiolm_pytorch)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq->audiolm_pytorch) (4.8)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm_pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm_pytorch) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm_pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->audiolm_pytorch) (2024.6.2)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (2.10.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (0.9.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (4.9.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->audiolm_pytorch) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1->audiolm_pytorch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->audiolm_pytorch) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->audiolm_pytorch)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: triton, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, docker-pycreds, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, einx, nvidia-cusolver-cu12, gitpython, wandb, torch, vector-quantize-pytorch, torchaudio, rotary-embedding-torch, pytorch-warmup, local-attention, ema-pytorch, accelerate, gateloop-transformer, audiolm_pytorch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.0.0\n","    Uninstalling triton-2.0.0:\n","      Successfully uninstalled triton-2.0.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1+cu117\n","    Uninstalling torch-2.0.1+cu117:\n","      Successfully uninstalled torch-2.0.1+cu117\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.0.2+cu117\n","    Uninstalling torchaudio-2.0.2+cu117:\n","      Successfully uninstalled torchaudio-2.0.2+cu117\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.15.2+cu117 requires torch==2.0.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.32.1 audiolm_pytorch-2.0.7 beartype-0.18.5 docker-pycreds-0.4.0 einx-0.3.0 ema-pytorch-0.5.1 gateloop-transformer-0.2.5 gitdb-4.0.11 gitpython-3.1.43 local-attention-1.9.14 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch-warmup-0.1.1 rotary-embedding-torch-0.6.4 sentry-sdk-2.8.0 setproctitle-1.3.3 smmap-5.0.1 torch-2.3.1 torchaudio-2.3.1 triton-2.3.1 vector-quantize-pytorch-1.15.1 wandb-0.17.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchaudio"]},"id":"f6f762a5ee5847458d2d4098a6ca0280"}},"metadata":{}}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"YUZl3ef3qIjQ","executionInfo":{"status":"ok","timestamp":1720484980489,"user_tz":-540,"elapsed":6784,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n","# Load HuBERT for semantic tokens\n","from hubert.pre_kmeans_hubert import CustomHubert\n","from hubert.customtokenizer import CustomTokenizer\n","\n","# Load the HuBERT model\n","hubert_model = CustomHubert(checkpoint_path='data/models/hubert/hubert.pt').to(device)\n","\n","# Load the CustomTokenizer model\n","tokenizer = CustomTokenizer.load_from_checkpoint('data/models/hubert/tokenizer.pth').to(device)  # Automatically uses the right layers"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"U3WmPY2TqIjQ","executionInfo":{"status":"ok","timestamp":1720485195541,"user_tz":-540,"elapsed":456,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["# Load and pre-process the audio waveform\n","audio_filepath = '/content/sample_data/audio_book_sample_cut_1.wav' # the audio you want to clone (under 13 seconds)\n","wav, sr = torchaudio.load(audio_filepath)\n","wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n","wav = wav.to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Rysgj2S7qIjR","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1720485198111,"user_tz":-540,"elapsed":893,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"df53b809-cbb8-46fe-f345-0b67c3806f57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Semantic vectors shape: torch.Size([312, 768])\n","Semantic tokens: tensor([5582,   10,  329,  282,  282, 1133, 5821, 9526, 9124, 4344, 1642,   41,\n","          41, 5143, 2785, 2785,  773,  120,   41,   41, 7238, 1319,  815,  815,\n","         815, 6399,  815,  815,  815, 3468, 6259,   50, 1892,  401,  401,  401,\n","        1355, 7980, 8230, 8230, 1421,   27,   27, 2399, 1232, 9526, 3286, 5400,\n","        5481, 2437, 3838, 3838, 2638, 6809, 5807, 5807, 6809,  245, 6734, 6734,\n","        6809, 6809, 6427,  462,  131, 5102, 5102, 5102,   10,  884, 4539, 9526,\n","        2785, 2785, 9914, 9914, 9914, 9914,  657,  657,  171,  321, 6504, 6504,\n","        9841, 5351,   10,   10, 3002, 3002, 3002, 3002, 7965, 7965, 7965, 7965,\n","        7965, 7965, 7965, 3042, 5955, 7965,   10,   27,   27,   27, 3971, 3971,\n","        2214,  456,  456, 1649, 1506, 4542, 9887, 7443,   50,   17,  719, 4996,\n","         973, 7255, 7255, 7255, 7255, 7255, 8231, 7890, 7463, 8230, 8230,  833,\n","          12,  282,  856, 1355, 3795,  466,   50,   27,   27,  778, 9526, 5887,\n","        5887, 5887, 3094, 3094, 4539, 4539, 4539,  648,  402, 4539, 9887, 5807,\n","        5807, 5807, 6734, 6809, 9526, 6809,  462,  462,  100, 1243, 1243, 7095,\n","        7095,  321,   41,   41, 8198, 8392, 8392, 2785, 4539, 2622,  620,   59,\n","          28,  107, 9717, 5084, 7891, 7802, 1421, 2519,   41,   41,  377, 4176,\n","        4176, 3110, 3110, 4150, 3378,  178,  532, 6587, 6587, 9878, 9878, 9526,\n","        2785, 2785, 6019, 1474, 1474,   10,  985,  131,   10, 4724,  830,  830,\n","        8605, 3214, 2021, 8017, 9812, 9812, 5499, 4928, 4539, 4539, 4539, 5677,\n","        6294, 6294, 5812, 8230, 8386,  196,  282, 1494, 8808, 6809, 6809,  207,\n","          59,   28,   28,  107, 1133, 4584, 7255,   41,   41, 9707, 4468,  191,\n","        8392, 8392, 4539, 8392,   41,   41, 7891, 7891, 1819,  557,  298, 6821,\n","        1808, 4228,   41,   41,   41,   41, 5029, 1912, 6545, 5245, 5245, 9765,\n","        9765, 2865, 2865,  326,  326,  211,   41,   41,  191, 5325, 7803, 9780,\n","         267,   59,   59,  107, 1032, 4539, 4539, 5189, 9843, 9843, 6583, 5500,\n","        5500, 5500, 5500, 1931, 1931, 1931, 4306, 4306, 7965,  266,  841,   10],\n","       device='cuda:0')\n"]}],"source":["semantic_vectors = hubert_model.forward(wav, input_sample_hz=model.sample_rate)\n","print(\"Semantic vectors shape:\", semantic_vectors.shape)\n","semantic_tokens = tokenizer.get_token(semantic_vectors)\n","print(\"Semantic tokens:\", semantic_tokens)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"9EMBUoqMqIjR","executionInfo":{"status":"ok","timestamp":1720485207845,"user_tz":-540,"elapsed":325,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["# Extract discrete codes from EnCodec\n","with torch.no_grad():\n","    encoded_frames = model.encode(wav.unsqueeze(0))\n","codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"SU2E6mBoqIjR","executionInfo":{"status":"ok","timestamp":1720485209062,"user_tz":-540,"elapsed":4,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["# move codes to cpu\n","codes = codes.cpu().numpy()\n","# move semantic tokens to cpu\n","semantic_tokens = semantic_tokens.cpu().numpy()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"MgEQELMVqIjS","executionInfo":{"status":"ok","timestamp":1720485211439,"user_tz":-540,"elapsed":333,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["import numpy as np\n","voice_name = 'test1' # whatever you want the name of the voice to be\n","output_path = '/content/sample_data/' + voice_name + '.npz'\n","np.savez(output_path, fine_prompt=codes, coarse_prompt=codes[:2, :], semantic_prompt=semantic_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93DXatfVqIjS"},"outputs":[],"source":["# That's it! Now you can head over to the generate.ipynb and use your voice_name for the 'history_prompt'"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"jg0GbXjNqIjS","executionInfo":{"status":"ok","timestamp":1720485213800,"user_tz":-540,"elapsed":333,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["from IPython.display import Audio"]},{"cell_type":"code","source":["def load_code_model(use_gpu=False):\n","    # 예시 코드로, 실제 모델 로딩 코드로 대체해야 합니다.\n","    import torch\n","    model = torch.nn.Module()  # 여기에 실제 모델을 로드하는 코드를 넣으세요.\n","    if use_gpu and torch.cuda.is_available():\n","        model = model.to('cuda')\n","    return model\n"],"metadata":{"id":"hV3Vf2KY7Qyr","executionInfo":{"status":"ok","timestamp":1720485484160,"user_tz":-540,"elapsed":332,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# 모델 GPU 사용 설정\n","model = load_code_model(use_gpu=True)\n","\n","def voice_clone(wav_path, wav_text, voice_name):\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    wav, sr = torchaudio.load(wav_path)\n","    wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n","    wav = wav.to(device)\n","\n","    # 오디오 데이터를 모델에 맞게 인코딩\n","    with torch.no_grad():\n","        encoded_frames = model.encode(wav)\n","    codes = torch.cat([f for f in encoded_frames], dim=-1).squeeze()  # [n, g, T]\n","\n","    # 오디오의 길이 계산\n","    seconds = wav.shape[-1] / model.sample_rate\n","    # 의미 있는 텍스트 토큰 생성\n","    semantic_tokens = generate_text_semantic(wav_text, max_gen_duration=seconds, top_k=50, top_p=0.95, temp=0.7)\n","\n","    # 출력 파일 경로 설정\n","    output_path = f\"/content/sample_data{voice_name}.npz\"\n","    np.savez(output_path, frame_prompt=codes, coarse_prompt=codes[::2, :], semantic_prompt=semantic_tokens)\n","\n","    return output_path\n","\n","# 예제 파일 사용\n","# output = voice_clone('mix1009.wav', 'Sample text for cloning.', 'example_voice')\n","# print(\"Generated voice clone output at:\", output)"],"metadata":{"id":"rpQIVuyd0zmC","executionInfo":{"status":"ok","timestamp":1720485485975,"user_tz":-540,"elapsed":384,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["wav_text = \"저번에 제가 올렸던 그 목요일에 제가 올렸던 영상은 좀 차분해졌으면 하는 마음에서.\"\n","voice_name = \"mix_voice\"\n","\n","# 음성 훈련 실행\n","voice_clone(\"/content/sample_data/audio_book_sample_cut_1.wav\", wav_text, \"mix_voice\")\n","\n","# 실행 결과를 다시 재생\n","Audio(\"mix_voice_2021.wav\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"EzjpgjTU0x_g","executionInfo":{"status":"error","timestamp":1720485506368,"user_tz":-540,"elapsed":381,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"554e8f94-4dfe-4775-b992-a63b1fab107e"},"execution_count":21,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'Module' object has no attribute 'sample_rate'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-1c12fcfec5bb>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 음성 훈련 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvoice_clone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/audio_book_sample_cut_1.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mix_voice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 실행 결과를 다시 재생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-24c9bc725c7e>\u001b[0m in \u001b[0;36mvoice_clone\u001b[0;34m(wav_path, wav_text, voice_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Module' object has no attribute 'sample_rate'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"eriZPZef1Lyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXPzHjg9qIjS"},"outputs":[],"source":["# Heres the generation stuff copy-pasted for convenience"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"IzaX915vqIjS","executionInfo":{"status":"ok","timestamp":1720450096526,"user_tz":-540,"elapsed":361,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[],"source":["from bark.api import generate_audio\n","from transformers import BertTokenizer\n","from bark.generation import SAMPLE_RATE, preload_models, codec_decode, generate_coarse, generate_fine, generate_text_semantic\n","\n","# Enter your prompt and speaker here\n","text_prompt = \"Hello, my name is Serpy. And, uh — and I like pizza. [laughs]\"\n","voice_name = \"output\" # use your custom voice name here if you have one"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jntz2B2VqIjT"},"outputs":[],"source":["# download and load all models\n","preload_models(\n","    text_use_gpu=True,\n","    text_use_small=False,\n","    coarse_use_gpu=True,\n","    coarse_use_small=False,\n","    fine_use_gpu=True,\n","    fine_use_small=False,\n","    codec_use_gpu=True,\n","    force_reload=False,\n","    path=\"models\"\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"0Cj2YSrUqIjT","colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"status":"error","timestamp":1720449576436,"user_tz":-540,"elapsed":347,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"781607f9-54f1-4678-f53a-4981aacea5ce"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'endswith'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-60d11f2388c8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# simple generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwaveform_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/bark-with-voice-clone/bark/api.py\u001b[0m in \u001b[0;36mgenerate_audio\u001b[0;34m(text, history_prompt, text_temp, waveform_temp, silent, output_full)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mnumpy\u001b[0m \u001b[0maudio\u001b[0m \u001b[0marray\u001b[0m \u001b[0mat\u001b[0m \u001b[0msample\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0mkhz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     semantic_tokens = text_to_semantic(\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mhistory_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bark-with-voice-clone/bark/api.py\u001b[0m in \u001b[0;36mtext_to_semantic\u001b[0;34m(text, history_prompt, temp, silent)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnumpy\u001b[0m \u001b[0msemantic\u001b[0m \u001b[0marray\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfed\u001b[0m \u001b[0minto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msemantic_to_waveform\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     x_semantic = generate_text_semantic(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mhistory_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bark-with-voice-clone/bark/generation.py\u001b[0m in \u001b[0;36mgenerate_text_semantic\u001b[0;34m(text, history_prompt, temp, top_k, top_p, silent, min_eos_p, max_gen_duration_s, allow_early_stop, use_kv_caching)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mmodels_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"text\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mpreload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0mmodel_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bark-with-voice-clone/bark/generation.py\u001b[0m in \u001b[0;36mpreload_models\u001b[0;34m(text_use_gpu, text_use_small, text_model_path, coarse_use_gpu, coarse_use_small, coarse_model_path, fine_use_gpu, fine_use_small, fine_model_path, codec_use_gpu, force_reload, path)\u001b[0m\n\u001b[1;32m    366\u001b[0m     ):\n\u001b[1;32m    367\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No GPU being used. Careful, inference might be very slow!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     _ = load_model(\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_use_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_small\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_use_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_model_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     )\n","\u001b[0;32m/content/bark-with-voice-clone/bark/generation.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(use_gpu, use_small, force_reload, model_type, path)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'endswith'"]}],"source":["# simple generation\n","audio_array = generate_audio(text_prompt, history_prompt=voice_name, text_temp=0.7, waveform_temp=0.7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vD5ovz-iqIjT"},"outputs":[],"source":["# generation with more control\n","x_semantic = generate_text_semantic(\n","    text_prompt,\n","    history_prompt=voice_name,\n","    temp=0.7,\n","    top_k=50,\n","    top_p=0.95,\n",")\n","\n","x_coarse_gen = generate_coarse(\n","    x_semantic,\n","    history_prompt=voice_name,\n","    temp=0.7,\n","    top_k=50,\n","    top_p=0.95,\n",")\n","x_fine_gen = generate_fine(\n","    x_coarse_gen,\n","    history_prompt=voice_name,\n","    temp=0.5,\n",")\n","audio_array = codec_decode(x_fine_gen)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lgzIGdLqIjT"},"outputs":[],"source":["from IPython.display import Audio\n","# play audio\n","Audio(audio_array, rate=SAMPLE_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iSpXPeYBqIjT"},"outputs":[],"source":["from scipy.io.wavfile import write as write_wav\n","# save audio\n","filepath = \"/output/audio.wav\" # change this to your desired output path\n","write_wav(filepath, SAMPLE_RATE, audio_array)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"https://github.com/serp-ai/bark-with-voice-clone/blob/main/clone_voice.ipynb","timestamp":1720447539364}],"gpuType":"L4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2de9c7790b39443d9720ca7ba35740bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25ae0a1132164cd3945f61ba297625fb","IPY_MODEL_955bfcf0413749afb3e64d58485f5898","IPY_MODEL_448b449c1f9f45ebb8ef1bb394025566"],"layout":"IPY_MODEL_e1e523696c4c473d9d6a52fba23b831c"}},"25ae0a1132164cd3945f61ba297625fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff468b00ed6a40898d12adbac51ff16e","placeholder":"​","style":"IPY_MODEL_8900dfe65f1f4394a6954fb2e450eda5","value":"quantifier_hubert_base_ls960_14.pth: 100%"}},"955bfcf0413749afb3e64d58485f5898":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_327c26a9111e4d63819fd270219a17a4","max":103981977,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fcac51c0f324b3b88a73ed13bf80192","value":103981977}},"448b449c1f9f45ebb8ef1bb394025566":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d015b7d0a0a406f8283b90de842f1cb","placeholder":"​","style":"IPY_MODEL_c1f605d8490b46f3be562844b96f1f8d","value":" 104M/104M [00:00&lt;00:00, 222MB/s]"}},"e1e523696c4c473d9d6a52fba23b831c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff468b00ed6a40898d12adbac51ff16e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8900dfe65f1f4394a6954fb2e450eda5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"327c26a9111e4d63819fd270219a17a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fcac51c0f324b3b88a73ed13bf80192":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d015b7d0a0a406f8283b90de842f1cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1f605d8490b46f3be562844b96f1f8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}