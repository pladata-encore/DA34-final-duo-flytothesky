{"cells":[{"cell_type":"markdown","source":["To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n","<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Join Discord if you need help + support us if you can!\n","</div>\n","\n","To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://github.com/unslothai/unsloth#installation-instructions---conda).\n","\n","You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n","\n","**[NEW] Llama-3 8b is trained on a crazy 15 trillion tokens! Llama-2 was 2 trillion.**"],"metadata":{"id":"IqM-T1RTzY6C"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"pkOiER7x_3F-","executionInfo":{"status":"ok","timestamp":1717986697358,"user_tz":-540,"elapsed":30103,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"325fcb72-db01-4ecf-dfa5-2e2091f42838","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","# Google Drive의 폴더 경로\n","folder_path = '/content/drive/MyDrive/02.라벨링데이터'\n","\n","# 폴더 내의 모든 파일 리스트 가져오기\n","file_list = os.listdir(folder_path)\n","\n","# ZIP 파일 찾기 및 풀기\n","for file_name in file_list:\n","    if file_name.endswith('.zip'):\n","        file_path = os.path.join(folder_path, file_name)\n","        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n","            zip_ref.extractall(folder_path)  # ZIP 파일을 동일한 폴더에 풉니다\n","            print(f'Extracted {file_name}')\n"],"metadata":{"id":"gZgcl8CO_23Q","executionInfo":{"status":"ok","timestamp":1717727936215,"user_tz":-540,"elapsed":8029923,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"36975c90-6084-4a23-8f12-7a533a1df9c4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted TL_단어_10대_여가.zip\n","Extracted TL_단어_10대_군대.zip\n","Extracted TL_문장_10대_가족.zip\n","Extracted TL_단어_10대_경제.zip\n","Extracted TL_문장_10대_직장.zip\n","Extracted TL_문장_10대_군대.zip\n","Extracted TL_단어_10대_연애결혼.zip\n","Extracted TL_단어_50대이상_여가.zip\n","Extracted TL_문장_10대_주거.zip\n","Extracted TL_단어_10대_주거.zip\n","Extracted TL_단어_10대_교육.zip\n","Extracted TL_문장_10대_연애결혼.zip\n","Extracted TL_단어_10대_직장.zip\n","Extracted TL_단어_10대_가족.zip\n","Extracted TL_단어_10대_음식.zip\n","Extracted TL_문장_10대_게임.zip\n","Extracted TL_단어_20대_여가.zip\n","Extracted TL_단어_10대_게임.zip\n","Extracted TL_단어_30대_여가.zip\n","Extracted TL_문장_50대이상_주거.zip\n","Extracted TL_단어_50대이상_가족.zip\n","Extracted TL_문장_10대_경제.zip\n","Extracted TL_문장_10대_여가.zip\n","Extracted TL_문장_50대이상_군대.zip\n","Extracted TL_단어_40대_여가.zip\n","Extracted TL_문장_10대_교육.zip\n","Extracted TL_문장_50대이상_게임.zip\n","Extracted TL_단어_20대_가족.zip\n","Extracted TL_문장_10대_음식.zip\n","Extracted TL_단어_50대이상_군대.zip\n","Extracted TL_단어_40대_가족.zip\n","Extracted TL_단어_50대이상_직장.zip\n","Extracted TL_단어_50대이상_주거.zip\n","Extracted TL_단어_30대_가족.zip\n","Extracted TL_문장_50대이상_가족.zip\n","Extracted TL_단어_40대_군대.zip\n","Extracted TL_문장_40대_군대.zip\n","Extracted TL_단어_50대이상_교육.zip\n","Extracted TL_단어_30대_군대.zip\n","Extracted TL_단어_30대_주거.zip\n","Extracted TL_문장_50대이상_음식.zip\n","Extracted TL_단어_20대_군대.zip\n","Extracted TL_단어_50대이상_연애결혼.zip\n","Extracted TL_단어_40대_주거.zip\n","Extracted TL_단어_50대이상_음식.zip\n","Extracted TL_단어_40대_직장.zip\n","Extracted TL_단어_20대_주거.zip\n","Extracted TL_단어_30대_직장.zip\n","Extracted TL_대화_50대이상_여가.zip\n","Extracted TL_문장_50대이상_경제.zip\n","Extracted TL_단어_20대_직장.zip\n","Extracted TL_대화_50대이상_가족.zip\n","Extracted TL_단어_40대_음식.zip\n","Extracted TL_단어_40대_연애결혼.zip\n","Extracted TL_단어_40대_교육.zip\n","Extracted TL_단어_50대이상_경제.zip\n","Extracted TL_단어_30대_음식.zip\n","Extracted TL_단어_30대_연애결혼.zip\n","Extracted TL_문장_50대이상_여가.zip\n","Extracted TL_문장_50대이상_연애결혼.zip\n","Extracted TL_대화_40대_여가.zip\n","Extracted TL_단어_30대_교육.zip\n","Extracted TL_문장_50대이상_직장.zip\n","Extracted TL_단어_10대_SNS.zip\n","Extracted TL_단어_20대_교육.zip\n","Extracted TL_문장_40대_가족.zip\n","Extracted TL_단어_20대_음식.zip\n","Extracted TL_단어_20대_연애결혼.zip\n","Extracted TL_단어_20대_경제.zip\n","Extracted TL_문장_40대_게임.zip\n","Extracted TL_단어_30대_경제.zip\n","Extracted TL_단어_40대_경제.zip\n","Extracted TL_단어_50대이상_게임.zip\n","Extracted TL_대화_50대이상_게임.zip\n","Extracted TL_문장_40대_여가.zip\n","Extracted TL_문장_40대_직장.zip\n","Extracted TL_단어_40대_게임.zip\n","Extracted TL_대화_50대이상_음식.zip\n","Extracted TL_문장_30대_여가.zip\n","Extracted TL_대화_10대_여가.zip\n","Extracted TL_문장_40대_주거.zip\n","Extracted TL_문장_30대_가족.zip\n","Extracted TL_문장_10대_SNS.zip\n","Extracted TL_문장_40대_연애결혼.zip\n","Extracted TL_대화_10대_가족.zip\n","Extracted TL_단어_30대_게임.zip\n","Extracted TL_대화_50대이상_교육.zip\n","Extracted TL_단어_20대_게임.zip\n","Extracted TL_문장_20대_가족.zip\n","Extracted TL_문장_30대_주거.zip\n","Extracted TL_문장_50대이상_교육.zip\n","Extracted TL_문장_30대_군대.zip\n","Extracted TL_문장_30대_연애결혼.zip\n","Extracted TL_대화_40대_가족.zip\n","Extracted TL_대화_40대_음식.zip\n","Extracted TL_문장_40대_음식.zip\n","Extracted TL_대화_10대_음식.zip\n","Extracted TL_대화_40대_게임.zip\n","Extracted TL_문장_20대_주거.zip\n","Extracted TL_문장_30대_게임.zip\n","Extracted TL_단어_10대_일상.zip\n","Extracted TL_문장_30대_음식.zip\n","Extracted TL_문장_40대_경제.zip\n","Extracted TL_문장_20대_여가.zip\n","Extracted TL_문장_20대_연애결혼.zip\n","Extracted TL_문장_30대_직장.zip\n","Extracted TL_문장_20대_군대.zip\n","Extracted TL_문장_40대_교육.zip\n","Extracted TL_대화_40대_교육.zip\n","Extracted TL_대화_50대이상_군대.zip\n","Extracted TL_대화_10대_게임.zip\n","Extracted TL_대화_50대이상_경제.zip\n","Extracted TL_문장_30대_경제.zip\n","Extracted TL_대화_10대_교육.zip\n","Extracted TL_문장_20대_직장.zip\n","Extracted TL_대화_30대_여가.zip\n","Extracted TL_문장_20대_게임.zip\n","Extracted TL_대화_50대이상_주거.zip\n","Extracted TL_단어_50대이상_SNS.zip\n","Extracted TL_문장_10대_일상.zip\n","Extracted TL_대화_40대_경제.zip\n","Extracted TL_대화_50대이상_직장.zip\n","Extracted TL_문장_20대_경제.zip\n","Extracted TL_문장_50대이상_SNS.zip\n","Extracted TL_대화_40대_군대.zip\n","Extracted TL_문장_20대_음식.zip\n","Extracted TL_대화_10대_군대.zip\n","Extracted TL_단어_20대_SNS.zip\n","Extracted TL_단어_40대_SNS.zip\n","Extracted TL_단어_30대_SNS.zip\n","Extracted TL_대화_10대_경제.zip\n","Extracted TL_문장_30대_교육.zip\n","Extracted TL_대화_10대_주거.zip\n","Extracted TL_대화_30대_가족.zip\n","Extracted TL_대화_40대_주거.zip\n","Extracted TL_대화_20대_여가.zip\n","Extracted TL_대화_30대_게임.zip\n","Extracted TL_대화_30대_음식.zip\n","Extracted TL_대화_50대이상_SNS.zip\n","Extracted TL_단어_50대이상_일상.zip\n","Extracted TL_문장_20대_교육.zip\n","Extracted TL_대화_30대_교육.zip\n","Extracted TL_대화_50대이상_연애결혼.zip\n","Extracted TL_문장_40대_SNS.zip\n","Extracted TL_대화_40대_직장.zip\n","Extracted TL_단어_40대_일상.zip\n","Extracted TL_단어_30대_일상.zip\n","Extracted TL_문장_50대이상_일상.zip\n","Extracted TL_대화_20대_가족.zip\n","Extracted TL_단어_20대_일상.zip\n","Extracted TL_대화_10대_직장.zip\n","Extracted TL_문장_30대_SNS.zip\n","Extracted TL_대화_30대_군대.zip\n","Extracted TL_대화_40대_연애결혼.zip\n","Extracted TL_대화_40대_SNS.zip\n","Extracted TL_대화_20대_음식.zip\n","Extracted TL_대화_30대_경제.zip\n","Extracted TL_대화_20대_게임.zip\n","Extracted TL_대화_10대_SNS.zip\n","Extracted TL_대화_10대_연애결혼.zip\n","Extracted TL_문장_40대_일상.zip\n","Extracted TL_문장_20대_SNS.zip\n","Extracted TL_대화_20대_교육.zip\n","Extracted TL_대화_30대_주거.zip\n","Extracted TL_대화_20대_군대.zip\n","Extracted TL_대화_30대_직장.zip\n","Extracted TL_대화_20대_경제.zip\n","Extracted TL_문장_30대_일상.zip\n","Extracted TL_대화_20대_주거.zip\n","Extracted TL_대화_30대_SNS.zip\n","Extracted TL_대화_30대_연애결혼.zip\n","Extracted TL_문장_20대_일상.zip\n","Extracted TL_대화_20대_직장.zip\n","Extracted TL_대화_50대이상_일상.zip\n","Extracted TL_대화_20대_SNS.zip\n","Extracted TL_대화_20대_연애결혼.zip\n","Extracted TL_대화_40대_일상.zip\n","Extracted TL_대화_10대_일상.zip\n","Extracted TL_대화_30대_일상.zip\n","Extracted TL_대화_20대_일상.zip\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","# JSON 파일이 있는 디렉토리\n","json_files_dir = '/content/drive/MyDrive/02.라벨링데이터'\n","\n","# 디렉토리 내의 JSON 파일 목록 가져오기\n","json_files = [f for f in os.listdir(json_files_dir) if f.endswith('.json')]\n","\n","# JSON 파일의 숫자 출력\n","print(f\"디렉토리 내의 JSON 파일 개수: {len(json_files)}\")\n","\n","# 첫 번째 JSON 파일의 내용 출력\n","if json_files:\n","    first_file_path = os.path.join(json_files_dir, json_files[0])\n","    with open(first_file_path, 'r', encoding='utf-8') as first_file:\n","        first_file_content = json.load(first_file)\n","\n","    # 첫 번째 파일의 내용 출력\n","    print(f\"첫 번째 JSON 파일 ({json_files[0]}) 내용:\")\n","    print(json.dumps(first_file_content, ensure_ascii=False, indent=4))\n","else:\n","    print(\"디렉토리에 JSON 파일이 없습니다.\")\n"],"metadata":{"id":"AsRmyVo0rIGf","executionInfo":{"status":"ok","timestamp":1717729793951,"user_tz":-540,"elapsed":3011,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"dce9a80d-9c3e-4dc1-ef2f-b9ad2ddd6d9d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["디렉토리 내의 JSON 파일 개수: 50552\n","첫 번째 JSON 파일 (10_13_2008_220812_0007.json) 내용:\n","{\n","    \"DataSet\": \"연령대별특징적발화음성\",\n","    \"Version\": \"1.0\",\n","    \"Date\": \"20220812\",\n","    \"MediaUrl\": \"단어/40대/교육/10_13_2008_220812_0007.wav\",\n","    \"DialogID\": \"10_13_2008_220812_0007\",\n","    \"Category\": \"40대\",\n","    \"SubCategory\": \"교육\",\n","    \"DialogPlace\": \"집\",\n","    \"DialogVoiceType\": \"독백\",\n","    \"SpeakerNumber\": \"1\",\n","    \"RecDevice\": \"스마트폰\",\n","    \"RecLen\": 3.679,\n","    \"AudioResolution\": {\n","        \"BitDepth\": \"16bit\",\n","        \"SampleRate\": \"44.1kHz\"\n","    },\n","    \"Speakers\": [\n","        {\n","            \"Speaker\": \"2008\",\n","            \"Gender\": \"남성\",\n","            \"Locate\": \"경상\",\n","            \"AgeGroup\": \"40\"\n","        }\n","    ],\n","    \"Dialogs\": [\n","        {\n","            \"DialogNum\": 1,\n","            \"Speaker\": \"2008\",\n","            \"SpeakerText\": \"광탈\",\n","            \"TextConvert\": \"광속으로 탈락\",\n","            \"StartTime\": 1.0,\n","            \"EndTime\": 2.679,\n","            \"SpeakTime\": 1.679,\n","            \"WordInfo\": [\n","                {\n","                    \"Word\": \"광탈\",\n","                    \"WordType\": \"은어\",\n","                    \"WordStructure\": \"기타\",\n","                    \"WordDefine\": \"대입전형 시 바로 즉시 탈락 된다는 의미'\",\n","                    \"WordFell\": \"부정\",\n","                    \"WordMean\": \"싫어함\"\n","                }\n","            ]\n","        }\n","    ]\n","}\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","from concurrent.futures import ProcessPoolExecutor, as_completed\n","import multiprocessing\n","\n","# JSON 파일들이 있는 디렉토리 경로\n","json_files_dir = '/content/drive/MyDrive/02.라벨링데이터'\n","\n","# 포맷 문자열\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","# Tokenizer EOS 토큰\n","EOS_TOKEN = '<EOS>'  # tokenizer.eos_token # Must add EOS_TOKEN\n","\n","# 변환 함수\n","def formatting_prompts_func(data):\n","    formatted_data = []\n","    for dialog in data[\"Dialogs\"]:\n","        text = alpaca_prompt.format(\n","            \"Translate the following slang to a more standard form.\",\n","            dialog[\"SpeakerText\"],\n","            dialog[\"TextConvert\"]\n","        ) + EOS_TOKEN\n","        formatted_data.append({\"text\": text})\n","    return formatted_data\n","\n","# JSON 파일을 처리하는 함수\n","def process_json_file(filename):\n","    json_file_path = os.path.join(json_files_dir, filename)\n","    try:\n","        # JSON 파일 열기\n","        with open(json_file_path, 'r', encoding='utf-8') as f:\n","            data = json.load(f)\n","\n","        # 변환 작업 수행\n","        return formatting_prompts_func(data)\n","    except ValueError as e:\n","        print(f'Error reading {json_file_path}: {e}')\n","        return []\n","\n","# 사용 가능한 CPU 코어 수 확인\n","num_cores = multiprocessing.cpu_count()\n","print(f'사용 가능한 CPU 코어 수: {num_cores}')\n","\n","# 모든 JSON 파일 순회 및 병렬 처리\n","if __name__ == \"__main__\":\n","    json_files = [f for f in os.listdir(json_files_dir) if f.endswith('.json')]\n","\n","    formatted_data = []\n","    batch_size = 100  # 주기적으로 저장할 배치 크기\n","    output_file_path = '/content/formatted_data_partial.json'\n","\n","    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n","        future_to_file = {executor.submit(process_json_file, filename): filename for filename in json_files}\n","\n","        for i, future in enumerate(as_completed(future_to_file)):\n","            result = future.result()\n","            formatted_data.extend(result)\n","\n","            # 주기적으로 데이터를 파일에 저장\n","            if (i + 1) % batch_size == 0:\n","                with open(output_file_path, 'w', encoding='utf-8') as f:\n","                    json.dump(formatted_data, f, indent=2, ensure_ascii=False)\n","                print(f'Partial data saved up to {i + 1} files.')\n","\n","    # 최종 결과 저장\n","    output_file_path = '/content/drive/MyDrive/formatted_data'\n","    with open(output_file_path, 'w', encoding='utf-8') as f:\n","        json.dump(formatted_data, f, indent=2, ensure_ascii=False)\n","\n","    print(f'The formatted data has been saved to {output_file_path}')\n","\n","    # 변환된 데이터 파일 열기 및 출력\n","    with open(output_file_path, 'r', encoding='utf-8') as f:\n","        formatted_data = json.load(f)\n","\n","    # JSON 데이터 출력\n","    print(json.dumps(formatted_data, indent=2, ensure_ascii=False))\n"],"metadata":{"id":"t_XvnIOP_2kG","executionInfo":{"status":"ok","timestamp":1717991409035,"user_tz":-540,"elapsed":4250446,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"883f1a08-1186-4e4b-e764-272586f9d9f6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["사용 가능한 CPU 코어 수: 8\n","Partial data saved up to 100 files.\n","Partial data saved up to 200 files.\n","Partial data saved up to 300 files.\n","Partial data saved up to 400 files.\n","Partial data saved up to 500 files.\n","Partial data saved up to 600 files.\n","Partial data saved up to 700 files.\n","Partial data saved up to 800 files.\n","Partial data saved up to 900 files.\n","Partial data saved up to 1000 files.\n","Partial data saved up to 1100 files.\n","Partial data saved up to 1200 files.\n","Partial data saved up to 1300 files.\n","Partial data saved up to 1400 files.\n","Partial data saved up to 1500 files.\n","Partial data saved up to 1600 files.\n","Partial data saved up to 1700 files.\n","Partial data saved up to 1800 files.\n","Partial data saved up to 1900 files.\n","Partial data saved up to 2000 files.\n","Partial data saved up to 2100 files.\n","Partial data saved up to 2200 files.\n","Partial data saved up to 2300 files.\n","Partial data saved up to 2400 files.\n","Partial data saved up to 2500 files.\n","Partial data saved up to 2600 files.\n","Partial data saved up to 2700 files.\n","Partial data saved up to 2800 files.\n","Partial data saved up to 2900 files.\n","Partial data saved up to 3000 files.\n","Partial data saved up to 3100 files.\n","Partial data saved up to 3200 files.\n","Partial data saved up to 3300 files.\n","Partial data saved up to 3400 files.\n","Partial data saved up to 3500 files.\n","Partial data saved up to 3600 files.\n","Partial data saved up to 3700 files.\n","Partial data saved up to 3800 files.\n","Partial data saved up to 3900 files.\n","Partial data saved up to 4000 files.\n","Partial data saved up to 4100 files.\n","Partial data saved up to 4200 files.\n","Partial data saved up to 4300 files.\n","Partial data saved up to 4400 files.\n","Partial data saved up to 4500 files.\n","Partial data saved up to 4600 files.\n","Partial data saved up to 4700 files.\n","Partial data saved up to 4800 files.\n","Partial data saved up to 4900 files.\n","Partial data saved up to 5000 files.\n","Partial data saved up to 5100 files.\n","Partial data saved up to 5200 files.\n","Partial data saved up to 5300 files.\n","Partial data saved up to 5400 files.\n","Partial data saved up to 5500 files.\n","Partial data saved up to 5600 files.\n","Partial data saved up to 5700 files.\n","Partial data saved up to 5800 files.\n","Partial data saved up to 5900 files.\n","Partial data saved up to 6000 files.\n","Partial data saved up to 6100 files.\n","Partial data saved up to 6200 files.\n","Partial data saved up to 6300 files.\n","Partial data saved up to 6400 files.\n","Partial data saved up to 6500 files.\n","Partial data saved up to 6600 files.\n","Partial data saved up to 6700 files.\n","Partial data saved up to 6800 files.\n","Partial data saved up to 6900 files.\n","Partial data saved up to 7000 files.\n","Partial data saved up to 7100 files.\n","Partial data saved up to 7200 files.\n","Partial data saved up to 7300 files.\n","Partial data saved up to 7400 files.\n","Partial data saved up to 7500 files.\n","Partial data saved up to 7600 files.\n","Partial data saved up to 7700 files.\n","Partial data saved up to 7800 files.\n","Partial data saved up to 7900 files.\n","Partial data saved up to 8000 files.\n","Partial data saved up to 8100 files.\n","Partial data saved up to 8200 files.\n","Partial data saved up to 8300 files.\n","Partial data saved up to 8400 files.\n","Partial data saved up to 8500 files.\n","Partial data saved up to 8600 files.\n","Partial data saved up to 8700 files.\n","Partial data saved up to 8800 files.\n","Partial data saved up to 8900 files.\n","Partial data saved up to 9000 files.\n","Partial data saved up to 9100 files.\n","Partial data saved up to 9200 files.\n","Partial data saved up to 9300 files.\n","Partial data saved up to 9400 files.\n","Partial data saved up to 9500 files.\n","Partial data saved up to 9600 files.\n","Partial data saved up to 9700 files.\n","Partial data saved up to 9800 files.\n","Partial data saved up to 9900 files.\n","Partial data saved up to 10000 files.\n","Partial data saved up to 10100 files.\n","Partial data saved up to 10200 files.\n","Partial data saved up to 10300 files.\n","Partial data saved up to 10400 files.\n","Partial data saved up to 10500 files.\n","Partial data saved up to 10600 files.\n","Partial data saved up to 10700 files.\n","Partial data saved up to 10800 files.\n","Partial data saved up to 10900 files.\n","Partial data saved up to 11000 files.\n","Partial data saved up to 11100 files.\n","Partial data saved up to 11200 files.\n","Partial data saved up to 11300 files.\n","Partial data saved up to 11400 files.\n","Partial data saved up to 11500 files.\n","Partial data saved up to 11600 files.\n","Partial data saved up to 11700 files.\n","Partial data saved up to 11800 files.\n","Partial data saved up to 11900 files.\n","Partial data saved up to 12000 files.\n","Partial data saved up to 12100 files.\n","Partial data saved up to 12200 files.\n","Partial data saved up to 12300 files.\n","Partial data saved up to 12400 files.\n","Partial data saved up to 12500 files.\n","Partial data saved up to 12600 files.\n","Partial data saved up to 12700 files.\n","Partial data saved up to 12800 files.\n","Partial data saved up to 12900 files.\n","Partial data saved up to 13000 files.\n","Partial data saved up to 13100 files.\n","Partial data saved up to 13200 files.\n","Partial data saved up to 13300 files.\n","Partial data saved up to 13400 files.\n","Partial data saved up to 13500 files.\n","Partial data saved up to 13600 files.\n","Partial data saved up to 13700 files.\n","Partial data saved up to 13800 files.\n","Partial data saved up to 13900 files.\n","Partial data saved up to 14000 files.\n","Partial data saved up to 14100 files.\n","Partial data saved up to 14200 files.\n","Partial data saved up to 14300 files.\n","Partial data saved up to 14400 files.\n","Partial data saved up to 14500 files.\n","Partial data saved up to 14600 files.\n","Partial data saved up to 14700 files.\n","Partial data saved up to 14800 files.\n","Partial data saved up to 14900 files.\n","Partial data saved up to 15000 files.\n","Partial data saved up to 15100 files.\n","Partial data saved up to 15200 files.\n","Partial data saved up to 15300 files.\n","Partial data saved up to 15400 files.\n","Partial data saved up to 15500 files.\n","Partial data saved up to 15600 files.\n","Partial data saved up to 15700 files.\n","Partial data saved up to 15800 files.\n","Partial data saved up to 15900 files.\n","Partial data saved up to 16000 files.\n","Partial data saved up to 16100 files.\n","Partial data saved up to 16200 files.\n","Partial data saved up to 16300 files.\n","Partial data saved up to 16400 files.\n","Partial data saved up to 16500 files.\n","Partial data saved up to 16600 files.\n","Partial data saved up to 16700 files.\n","Partial data saved up to 16800 files.\n","Partial data saved up to 16900 files.\n","Partial data saved up to 17000 files.\n","Partial data saved up to 17100 files.\n","Partial data saved up to 17200 files.\n","Partial data saved up to 17300 files.\n","Partial data saved up to 17400 files.\n","Partial data saved up to 17500 files.\n","Partial data saved up to 17600 files.\n","Partial data saved up to 17700 files.\n","Partial data saved up to 17800 files.\n","Partial data saved up to 17900 files.\n","Partial data saved up to 18000 files.\n","Partial data saved up to 18100 files.\n","Partial data saved up to 18200 files.\n","Partial data saved up to 18300 files.\n","Partial data saved up to 18400 files.\n","Partial data saved up to 18500 files.\n","Partial data saved up to 18600 files.\n","Partial data saved up to 18700 files.\n","Partial data saved up to 18800 files.\n","Partial data saved up to 18900 files.\n","Partial data saved up to 19000 files.\n","Partial data saved up to 19100 files.\n","Partial data saved up to 19200 files.\n","Partial data saved up to 19300 files.\n","Partial data saved up to 19400 files.\n","Partial data saved up to 19500 files.\n","Partial data saved up to 19600 files.\n","Partial data saved up to 19700 files.\n","Partial data saved up to 19800 files.\n","Partial data saved up to 19900 files.\n","Partial data saved up to 20000 files.\n","Partial data saved up to 20100 files.\n","Partial data saved up to 20200 files.\n","Partial data saved up to 20300 files.\n","Partial data saved up to 20400 files.\n","Partial data saved up to 20500 files.\n","Partial data saved up to 20600 files.\n","Partial data saved up to 20700 files.\n","Partial data saved up to 20800 files.\n","Partial data saved up to 20900 files.\n","Partial data saved up to 21000 files.\n","Partial data saved up to 21100 files.\n","Partial data saved up to 21200 files.\n","Partial data saved up to 21300 files.\n","Partial data saved up to 21400 files.\n","Partial data saved up to 21500 files.\n","Partial data saved up to 21600 files.\n","Partial data saved up to 21700 files.\n","Partial data saved up to 21800 files.\n","Partial data saved up to 21900 files.\n","Partial data saved up to 22000 files.\n","Partial data saved up to 22100 files.\n","Partial data saved up to 22200 files.\n","Partial data saved up to 22300 files.\n","Partial data saved up to 22400 files.\n","Partial data saved up to 22500 files.\n","Partial data saved up to 22600 files.\n","Partial data saved up to 22700 files.\n","Partial data saved up to 22800 files.\n","Partial data saved up to 22900 files.\n","Partial data saved up to 23000 files.\n","Partial data saved up to 23100 files.\n","Partial data saved up to 23200 files.\n","Partial data saved up to 23300 files.\n","Partial data saved up to 23400 files.\n","Partial data saved up to 23500 files.\n","Partial data saved up to 23600 files.\n","Partial data saved up to 23700 files.\n","Partial data saved up to 23800 files.\n","Partial data saved up to 23900 files.\n","Partial data saved up to 24000 files.\n","Partial data saved up to 24100 files.\n","Partial data saved up to 24200 files.\n","Partial data saved up to 24300 files.\n","Partial data saved up to 24400 files.\n","Partial data saved up to 24500 files.\n","Partial data saved up to 24600 files.\n","Partial data saved up to 24700 files.\n","Partial data saved up to 24800 files.\n","Partial data saved up to 24900 files.\n","Partial data saved up to 25000 files.\n","Partial data saved up to 25100 files.\n","Partial data saved up to 25200 files.\n","Partial data saved up to 25300 files.\n","Partial data saved up to 25400 files.\n","Partial data saved up to 25500 files.\n","Partial data saved up to 25600 files.\n","Partial data saved up to 25700 files.\n","Partial data saved up to 25800 files.\n","Partial data saved up to 25900 files.\n","Partial data saved up to 26000 files.\n","Partial data saved up to 26100 files.\n","Partial data saved up to 26200 files.\n","Partial data saved up to 26300 files.\n","Partial data saved up to 26400 files.\n","Partial data saved up to 26500 files.\n","Partial data saved up to 26600 files.\n","Partial data saved up to 26700 files.\n","Partial data saved up to 26800 files.\n","Partial data saved up to 26900 files.\n","Partial data saved up to 27000 files.\n","Partial data saved up to 27100 files.\n","Partial data saved up to 27200 files.\n","Partial data saved up to 27300 files.\n","Partial data saved up to 27400 files.\n","Partial data saved up to 27500 files.\n","Partial data saved up to 27600 files.\n","Partial data saved up to 27700 files.\n","Partial data saved up to 27800 files.\n","Partial data saved up to 27900 files.\n","Partial data saved up to 28000 files.\n","Partial data saved up to 28100 files.\n","Partial data saved up to 28200 files.\n","Partial data saved up to 28300 files.\n","Partial data saved up to 28400 files.\n","Partial data saved up to 28500 files.\n","Partial data saved up to 28600 files.\n","Partial data saved up to 28700 files.\n","Partial data saved up to 28800 files.\n","Partial data saved up to 28900 files.\n","Partial data saved up to 29000 files.\n","Partial data saved up to 29100 files.\n","Partial data saved up to 29200 files.\n","Partial data saved up to 29300 files.\n","Partial data saved up to 29400 files.\n","Partial data saved up to 29500 files.\n","Partial data saved up to 29600 files.\n","Partial data saved up to 29700 files.\n","Partial data saved up to 29800 files.\n","Partial data saved up to 29900 files.\n","Partial data saved up to 30000 files.\n","Partial data saved up to 30100 files.\n","Partial data saved up to 30200 files.\n","Partial data saved up to 30300 files.\n","Partial data saved up to 30400 files.\n","Partial data saved up to 30500 files.\n","Partial data saved up to 30600 files.\n","Partial data saved up to 30700 files.\n","Partial data saved up to 30800 files.\n","Partial data saved up to 30900 files.\n","Partial data saved up to 31000 files.\n","Partial data saved up to 31100 files.\n","Partial data saved up to 31200 files.\n","Partial data saved up to 31300 files.\n","Partial data saved up to 31400 files.\n","Partial data saved up to 31500 files.\n","Partial data saved up to 31600 files.\n","Partial data saved up to 31700 files.\n","Partial data saved up to 31800 files.\n","Partial data saved up to 31900 files.\n","Partial data saved up to 32000 files.\n","Partial data saved up to 32100 files.\n","Partial data saved up to 32200 files.\n","Partial data saved up to 32300 files.\n","Partial data saved up to 32400 files.\n","Partial data saved up to 32500 files.\n","Partial data saved up to 32600 files.\n","Partial data saved up to 32700 files.\n","Partial data saved up to 32800 files.\n","Partial data saved up to 32900 files.\n","Partial data saved up to 33000 files.\n","Partial data saved up to 33100 files.\n","Partial data saved up to 33200 files.\n","Partial data saved up to 33300 files.\n","Partial data saved up to 33400 files.\n","Partial data saved up to 33500 files.\n","Partial data saved up to 33600 files.\n","Partial data saved up to 33700 files.\n","Partial data saved up to 33800 files.\n","Partial data saved up to 33900 files.\n","Partial data saved up to 34000 files.\n","Partial data saved up to 34100 files.\n","Partial data saved up to 34200 files.\n","Partial data saved up to 34300 files.\n","Partial data saved up to 34400 files.\n","Partial data saved up to 34500 files.\n","Partial data saved up to 34600 files.\n","Partial data saved up to 34700 files.\n","Partial data saved up to 34800 files.\n","Partial data saved up to 34900 files.\n","Partial data saved up to 35000 files.\n","Partial data saved up to 35100 files.\n","Partial data saved up to 35200 files.\n","Partial data saved up to 35300 files.\n","Partial data saved up to 35400 files.\n","Partial data saved up to 35500 files.\n","Partial data saved up to 35600 files.\n","Partial data saved up to 35700 files.\n","Partial data saved up to 35800 files.\n","Partial data saved up to 35900 files.\n","Partial data saved up to 36000 files.\n","Partial data saved up to 36100 files.\n","Partial data saved up to 36200 files.\n","Partial data saved up to 36300 files.\n","Partial data saved up to 36400 files.\n","Partial data saved up to 36500 files.\n","Partial data saved up to 36600 files.\n","Partial data saved up to 36700 files.\n","Partial data saved up to 36800 files.\n","Partial data saved up to 36900 files.\n","Partial data saved up to 37000 files.\n","Partial data saved up to 37100 files.\n","Partial data saved up to 37200 files.\n","Partial data saved up to 37300 files.\n","Partial data saved up to 37400 files.\n","Partial data saved up to 37500 files.\n","Partial data saved up to 37600 files.\n","Partial data saved up to 37700 files.\n","Partial data saved up to 37800 files.\n","Partial data saved up to 37900 files.\n","Partial data saved up to 38000 files.\n","Partial data saved up to 38100 files.\n","Partial data saved up to 38200 files.\n","Partial data saved up to 38300 files.\n","Partial data saved up to 38400 files.\n","Partial data saved up to 38500 files.\n","Partial data saved up to 38600 files.\n","Partial data saved up to 38700 files.\n","Partial data saved up to 38800 files.\n","Partial data saved up to 38900 files.\n","Partial data saved up to 39000 files.\n","Partial data saved up to 39100 files.\n","Partial data saved up to 39200 files.\n","Partial data saved up to 39300 files.\n","Partial data saved up to 39400 files.\n","Partial data saved up to 39500 files.\n","Partial data saved up to 39600 files.\n","Partial data saved up to 39700 files.\n","Partial data saved up to 39800 files.\n","Partial data saved up to 39900 files.\n","Partial data saved up to 40000 files.\n","Partial data saved up to 40100 files.\n","Partial data saved up to 40200 files.\n","Partial data saved up to 40300 files.\n","Partial data saved up to 40400 files.\n","Partial data saved up to 40500 files.\n","Partial data saved up to 40600 files.\n","Partial data saved up to 40700 files.\n","Partial data saved up to 40800 files.\n","Partial data saved up to 40900 files.\n","Partial data saved up to 41000 files.\n","Partial data saved up to 41100 files.\n","Partial data saved up to 41200 files.\n","Partial data saved up to 41300 files.\n","Partial data saved up to 41400 files.\n","Partial data saved up to 41500 files.\n","Partial data saved up to 41600 files.\n","Partial data saved up to 41700 files.\n","Partial data saved up to 41800 files.\n","Partial data saved up to 41900 files.\n","Partial data saved up to 42000 files.\n","Partial data saved up to 42100 files.\n","Partial data saved up to 42200 files.\n","Partial data saved up to 42300 files.\n","Partial data saved up to 42400 files.\n","Partial data saved up to 42500 files.\n","Partial data saved up to 42600 files.\n","Partial data saved up to 42700 files.\n","Partial data saved up to 42800 files.\n","Partial data saved up to 42900 files.\n","Partial data saved up to 43000 files.\n","Partial data saved up to 43100 files.\n","Partial data saved up to 43200 files.\n","Partial data saved up to 43300 files.\n","Partial data saved up to 43400 files.\n","Partial data saved up to 43500 files.\n","Partial data saved up to 43600 files.\n","Partial data saved up to 43700 files.\n","Partial data saved up to 43800 files.\n","Partial data saved up to 43900 files.\n","Partial data saved up to 44000 files.\n","Partial data saved up to 44100 files.\n","Partial data saved up to 44200 files.\n","Partial data saved up to 44300 files.\n","Partial data saved up to 44400 files.\n","Partial data saved up to 44500 files.\n","Partial data saved up to 44600 files.\n","Partial data saved up to 44700 files.\n","Partial data saved up to 44800 files.\n","Partial data saved up to 44900 files.\n","Partial data saved up to 45000 files.\n","Partial data saved up to 45100 files.\n","Partial data saved up to 45200 files.\n","Partial data saved up to 45300 files.\n","Partial data saved up to 45400 files.\n","Partial data saved up to 45500 files.\n","Partial data saved up to 45600 files.\n","Partial data saved up to 45700 files.\n","Partial data saved up to 45800 files.\n","Partial data saved up to 45900 files.\n","Partial data saved up to 46000 files.\n","Partial data saved up to 46100 files.\n","Partial data saved up to 46200 files.\n","Partial data saved up to 46300 files.\n","Partial data saved up to 46400 files.\n","Partial data saved up to 46500 files.\n","Partial data saved up to 46600 files.\n","Partial data saved up to 46700 files.\n","Partial data saved up to 46800 files.\n","Partial data saved up to 46900 files.\n","Partial data saved up to 47000 files.\n","Partial data saved up to 47100 files.\n","Partial data saved up to 47200 files.\n","Partial data saved up to 47300 files.\n","Partial data saved up to 47400 files.\n","Partial data saved up to 47500 files.\n","Partial data saved up to 47600 files.\n","Partial data saved up to 47700 files.\n","Partial data saved up to 47800 files.\n","Partial data saved up to 47900 files.\n","Partial data saved up to 48000 files.\n","Partial data saved up to 48100 files.\n","Partial data saved up to 48200 files.\n","Partial data saved up to 48300 files.\n","Partial data saved up to 48400 files.\n","Partial data saved up to 48500 files.\n","Partial data saved up to 48600 files.\n","Partial data saved up to 48700 files.\n","Partial data saved up to 48800 files.\n","Partial data saved up to 48900 files.\n","Partial data saved up to 49000 files.\n","Partial data saved up to 49100 files.\n","Partial data saved up to 49200 files.\n","Partial data saved up to 49300 files.\n","Partial data saved up to 49400 files.\n","Partial data saved up to 49500 files.\n","Partial data saved up to 49600 files.\n","Partial data saved up to 49700 files.\n","Partial data saved up to 49800 files.\n","Partial data saved up to 49900 files.\n","Partial data saved up to 50000 files.\n","Partial data saved up to 50100 files.\n","Partial data saved up to 50200 files.\n","Partial data saved up to 50300 files.\n","Partial data saved up to 50400 files.\n","Partial data saved up to 50500 files.\n","The formatted data has been saved to /content/drive/MyDrive/formatted_data\n"]},{"output_type":"stream","name":"stderr","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}]},{"cell_type":"code","source":["len(formatted_data)\n","output_file_path = '/content/formatted_data_final.json'\n","with open(output_file_path, 'w', encoding='utf-8') as f:\n","    json.dump(formatted_data, f, indent=2, ensure_ascii=False)\n","\n","print(f'The formatted data has been saved to {output_file_path}')\n","\n","# 변환된 데이터 파일 열기 및 출력\n","with open(output_file_path, 'r', encoding='utf-8') as f:\n","    formatted_data = json.load(f)"],"metadata":{"id":"L8n1zYehHn9q","executionInfo":{"status":"ok","timestamp":1717740546009,"user_tz":-540,"elapsed":1322,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"dd83d99e-9da9-43d6-ea73-d5f602cdbf01","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The formatted data has been saved to /content/formatted_data_final.json\n"]}]},{"cell_type":"code","source":["len(formatted_data)"],"metadata":{"id":"9bJDVepp_1_V","executionInfo":{"status":"ok","timestamp":1717740554378,"user_tz":-540,"elapsed":802,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"4df5b224-e2c9-4925-d77a-7a236da68ee3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50552"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eSvM9zX_2d3"},"outputs":[],"source":["%%capture\n","import torch\n","major_version, minor_version = torch.cuda.get_device_capability()\n","# Must install separately since Colab has torch 2.2.1, which breaks packages\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","if major_version >= 8:\n","    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n","    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n","else:\n","    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n","    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n","pass"]},{"cell_type":"markdown","source":["* We support Llama, Mistral, CodeLlama, TinyLlama, Vicuna, Open Hermes etc\n","* And Yi, Qwen ([llamafied](https://huggingface.co/models?sort=trending&search=qwen+llama)), Deepseek, all Llama, Mistral derived archs.\n","* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n","* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n","* [**NEW**] With [PR 26037](https://github.com/huggingface/transformers/pull/26037), we support downloading 4bit models **4x faster**! [Our repo](https://huggingface.co/unsloth) has Llama, Mistral 4bit models."],"metadata":{"id":"r2v_X2fA0Df5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmUBVEnvCDJv","executionInfo":{"status":"ok","timestamp":1717741143223,"user_tz":-540,"elapsed":7167,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"022aefb9-1236-487b-92af-8028eac80d5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Fast Llama patching release 2024.5\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. Xformers = 0.0.26.post1. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","# fourbit_models = [\n","#     \"unsloth/mistral-7b-bnb-4bit\",\n","#     \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","#     \"unsloth/llama-2-7b-bnb-4bit\",\n","#     \"unsloth/gemma-7b-bnb-4bit\",\n","#     \"unsloth/gemma-7b-it-bnb-4bit\", # Instruct version of Gemma 7b\n","#     \"unsloth/gemma-2b-bnb-4bit\",\n","#     \"unsloth/gemma-2b-it-bnb-4bit\", # Instruct version of Gemma 2b\n","#     \"unsloth/llama-3-8b-bnb-4bit\", # [NEW] 15 Trillion token Llama-3\n","# ] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","source":["We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"],"metadata":{"id":"SXd9bTZd1aaL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bZsfBuZDeCL"},"outputs":[],"source":[" model = FastLanguageModel.get_peft_model(\n","     model,\n","     r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                       \"gate_proj\", \"up_proj\", \"down_proj\",],\n","     lora_alpha = 16,\n","     lora_dropout = 0, # Supports any, but = 0 is optimized\n","     bias = \"none\",    # Supports any, but = \"none\" is optimized\n","     # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","     use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","     random_state = 3407,\n","     use_rslora = False,  # We support rank stabilized LoRA\n","     loftq_config = None, # And LoftQ\n"," )"]},{"cell_type":"markdown","source":["<a name=\"Data\"></a>\n","### Data Prep\n","We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n","\n","**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n","\n","**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n","\n","If you want to use the `ChatML` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing).\n","\n","For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."],"metadata":{"id":"vITh0KVJ10qX"}},{"cell_type":"code","source":[],"metadata":{"id":"hk1LVCrsk8jE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","dataset = formatted_data\n","#from datasets import load_dataset\n","#dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n","#dataset = dataset.map(formatting_prompts_func, batched = True,)\n","\n","# datasets.Dataset 형식으로 변환\n","dataset = Dataset.from_dict({\"text\": [entry[\"text\"] for entry in formatted_data]})\n","\n","# 데이터 확인\n","print(dataset)\n","print(formatted_data[1:100])"],"metadata":{"id":"r9274zRcIX9m","executionInfo":{"status":"ok","timestamp":1717742531908,"user_tz":-540,"elapsed":693,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"e919fddb-7bbe-48d7-edb1-8cfdd91f058c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text'],\n","    num_rows: 50552\n","})\n","[{'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여미새\\n\\n### Response:\\n여자에 미친새끼<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n완소남\\n\\n### Response:\\n완전 소중한 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여혐\\n\\n### Response:\\n여성혐오<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n자만추\\n\\n### Response:\\n자연스런 만남 추구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n완소녀\\n\\n### Response:\\n완전 소중한 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여친\\n\\n### Response:\\n여자친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n까도남\\n\\n### Response:\\n까칠하고 도도한 남자, 까칠한 도시 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n고스팅\\n\\n### Response:\\n관계를 유지하던 상대가 갑자기 잠적하는 거<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n너드미\\n\\n### Response:\\n순수하고 착한 모범생 같은 아름다움<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n유교걸\\n\\n### Response:\\n보수적인 여성<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n차도남\\n\\n### Response:\\n차가운 도시 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n과씨씨\\n\\n### Response:\\n같은 대학 같은 학과서 사귀던 연인<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n금사빠\\n\\n### Response:\\n금방 사랑에 빠진다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n걸조\\n\\n### Response:\\n걸어 다니는 조각상<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n얼빵\\n\\n### Response:\\n얼굴 못생김<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n얼짱\\n\\n### Response:\\n얼굴 최고<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여소\\n\\n### Response:\\n여자소개<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뇌섹남\\n\\n### Response:\\n똑똑한 남성<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n롱디\\n\\n### Response:\\n장거리 연예<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n만찢남녀\\n\\n### Response:\\n만화 속 인물처럼 외모가 출중한 남녀<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n멋쁨\\n\\n### Response:\\n멋지고 예쁘다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n속도위반결혼\\n\\n### Response:\\n의도치 않은 임신으로 결혼하는 상황<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n볼매\\n\\n### Response:\\n볼수록 매력있다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n스드메\\n\\n### Response:\\n스튜디오-웨딩드레스-메이크업 <EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n미도남\\n\\n### Response:\\n미지근한 도시의 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n아만추\\n\\n### Response:\\n아무나 만남 추구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n알파메일\\n\\n### Response:\\n뭐든지 잘하는 남성<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n전남친\\n\\n### Response:\\n전 남자친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n훈남\\n\\n### Response:\\n훈훈한 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n남미새\\n\\n### Response:\\n남자에 미친새끼<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n그린라이트\\n\\n### Response:\\n상대가 호감을 갖고 있으니 다가가도 된다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n개팅\\n\\n### Response:\\n소개팅<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여혐\\n\\n### Response:\\n여성혐오<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n씨씨\\n\\n### Response:\\n같은 대학교서 맺어진 커플<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여사친\\n\\n### Response:\\n성별이 여자인 그냥 친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n인만추\\n\\n### Response:\\n인위적인 만남 추구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n찐사랑\\n\\n### Response:\\n굉장한 사랑<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n초식남\\n\\n### Response:\\n연애에 소극적이고 관심 없는 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n졸귀\\n\\n### Response:\\n졸라 귀엽다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n차도녀\\n\\n### Response:\\n차가운 도시 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n훈녀\\n\\n### Response:\\n훈훈한 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n존잘\\n\\n### Response:\\n존나 잘생겼다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n존예\\n\\n### Response:\\n존나 예쁘다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n랜선연애\\n\\n### Response:\\n사이버 공간 연예<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n남소\\n\\n### Response:\\n남자 소개<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n당나귀\\n\\n### Response:\\n당신은 나의 귀염둥이<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꾸안꾸\\n\\n### Response:\\n꾸민듯 안 꾸민듯<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n구남친\\n\\n### Response:\\n전 남자친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n남친룩\\n\\n### Response:\\n남자친구가 입어줬음 하거나 입히고싶은 옷<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n너드녀\\n\\n### Response:\\n순수하고 착한 모범생 같은 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n남친룩\\n\\n### Response:\\n남자친구가 입어줬음 하거나 입히고싶은 옷<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n연서복\\n\\n### Response:\\n연애에 서툰 복학생<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n전여친\\n\\n### Response:\\n전 여자친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n우유남\\n\\n### Response:\\n우월한 유전자 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여혐\\n\\n### Response:\\n여성혐오<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n존못\\n\\n### Response:\\n존나 못생겼다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n썸\\n\\n### Response:\\n사귀진 않지만 미묘한 관계<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n여친\\n\\n### Response:\\n여자친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n유교보이\\n\\n### Response:\\n보수적인 남성<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n존못\\n\\n### Response:\\n존나 못생겼다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n너드녀\\n\\n### Response:\\n순수하고 착한 모범생 같은 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n썸\\n\\n### Response:\\n사귀진 않지만 미묘한 관계<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n완소남\\n\\n### Response:\\n완전 소중한 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n삼귀다\\n\\n### Response:\\n사귀기 전 단계<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n그린라이트\\n\\n### Response:\\n상대가 호감을 갖고 있으니 다가가도 된다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n돌싱\\n\\n### Response:\\n돌아온 싱글<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n가싶녀\\n\\n### Response:\\n가지고싶을 정도의 예쁘거나 매력있는 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n구여친\\n\\n### Response:\\n전 여자친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n갈비\\n\\n### Response:\\n갈수록 비호감<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n까도녀\\n\\n### Response:\\n까칠하고 도도한 여자, 까칠한 도시 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n남사친\\n\\n### Response:\\n성별이 남자인 그냥 친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n티키타카\\n\\n### Response:\\n대화가 잘 통하는 상황<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n매너남\\n\\n### Response:\\n매너 있는 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n가싶녀\\n\\n### Response:\\n가지고싶을 정도의 예쁘거나 매력있는 여자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n만찢남\\n\\n### Response:\\n만화 속 인물처럼 외모가 출중한 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n비혼\\n\\n### Response:\\n혼인하지 않음<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n심쿵\\n\\n### Response:\\n심장이 쿵했다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n낮져밤이\\n\\n### Response:\\n낮앤 져 주고 밤엔 이긴다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꾸꾸꾸\\n\\n### Response:\\n꾸민듯 꾸민듯 꾸밈<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n남아공\\n\\n### Response:\\n남아서 공부나 해라<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n부없남\\n\\n### Response:\\n부러울게 없는 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n돼지엄마\\n\\n### Response:\\n자녀교육에 투자를 아끼지 않는 엄마<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n너드남\\n\\n### Response:\\n순수하고 착한 모범생 같은 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n담탱이\\n\\n### Response:\\n담임선생님<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뇌섹녀\\n\\n### Response:\\n똑똑한 여성<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꼬댕이\\n\\n### Response:\\n공부도 못하고 놀지도 못하는 학생<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n번따\\n\\n### Response:\\n전화번호를 주거나 받는 행위<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n과떨이\\n\\n### Response:\\n과학고에서 떨어진 학생<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n코로나결혼\\n\\n### Response:\\n코로나로 인한 외로움으로 결혼 문의가 증가하는 현상<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n서카포유지디\\n\\n### Response:\\n서울대, 카이스트, 포스텍, 유니스트, 지스트, 디지스트<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n부없남\\n\\n### Response:\\n부러울게 없는 남자<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n둥지족\\n\\n### Response:\\n학교라는 둥지를 벗어나지 않는 종족<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n광탈\\n\\n### Response:\\n광속으로 탈락<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꼬댕이\\n\\n### Response:\\n공부도 못하고 놀지도 못하는 학생<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n구여친\\n\\n### Response:\\n전 여자친구<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n문송하다\\n\\n### Response:\\n문과라서 죄송하다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n존못\\n\\n### Response:\\n존나 못생겼다<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n급식체\\n\\n### Response:\\n십대들 사이의 유행어<EOS>'}, {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n교튽\\n\\n### Response:\\n교장<EOS>'}]\n"]}]},{"cell_type":"markdown","source":["<a name=\"Train\"></a>\n","### Train the model\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"],"metadata":{"id":"idAEIeSQ3xdS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"95_Nn-89DhsL","colab":{"base_uri":"https://localhost:8080/","height":305,"referenced_widgets":["c102dab5237f40bd92e8233312102ea1","18bf58832db245afbb0289f4fd2f1419","e53621814479427e982aeefe7156eff4","a96ab655d20f46ccb4644b8fa231e99c","26e13d28bf684bfa89a22dd6f810e932","edc1d4706df541938ddd0309160535c5","ce94a53b6df84d5692184673d1af2821","1db5248c3ceb4803a8b64804ffa1dfa2","3d9d7b02ce004076b5a314877c8941f1","2e4e0fceb42d47abb64d14b407aede7b","d66ca205de864ef7a6c1d73b1cf3b3a9"]},"executionInfo":{"status":"ok","timestamp":1717742545989,"user_tz":-540,"elapsed":9658,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"cf66bb1c-0022-4d7c-ce3e-083c56235d37"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `dataset_num_proc` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/50552 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c102dab5237f40bd92e8233312102ea1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n","max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ejIt2xSNKKp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717741778036,"user_tz":-540,"elapsed":780,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"184c91fe-fbfb-45aa-d996-925316a37c95"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","14.582 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"S5GL4zcFZvkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yqxqAZ7KJ4oL","colab":{"base_uri":"https://localhost:8080/","height":603},"outputId":"3c0c403d-4738-49a9-c615-0587589e8c16","executionInfo":{"status":"error","timestamp":1717742576105,"user_tz":-540,"elapsed":24409,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 50,552 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='7' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 7/60 00:14 < 02:37, 0.34 it/s, Epoch 0.00/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.315200</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.059700</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.638300</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.835800</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.323000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 300.00 MiB. GPU ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-3d62c575fcfd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/tokenizer_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3264\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3265\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mconvert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    787\u001b[0m         )\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecursively_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_to_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_is_fp16_bf16_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         return type(data)(\n\u001b[0;32m--> 118\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    119\u001b[0m                 k: recursively_apply(\n\u001b[1;32m    120\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_on_other_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m         return type(data)(\n\u001b[1;32m    118\u001b[0m             {\n\u001b[0;32m--> 119\u001b[0;31m                 k: recursively_apply(\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_on_other_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         raise TypeError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m_convert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_fp16_bf16_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 300.00 MiB. GPU "]}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCqnaKmlO1U9","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713475397667,"user_tz":420,"elapsed":166,"user":{"displayName":"Prompt Engineering","userId":"07913740242331449447"}},"outputId":"54abcba3-1d6f-4fa8-d782-d620743f7ddc"},"outputs":[{"output_type":"stream","name":"stdout","text":["462.0133 seconds used for training.\n","7.7 minutes used for training.\n","Peak reserved memory = 8.982 GB.\n","Peak reserved memory for training = 3.314 GB.\n","Peak reserved memory % of max memory = 60.903 %.\n","Peak reserved memory for training % of max memory = 22.471 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!"],"metadata":{"id":"ekOmTR1hSNcr"}},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Continue the fibonnaci sequence.\", # instruction\n","        \"1, 1, 2, 3, 5, 8\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"],"metadata":{"id":"kR3gIAX-SM2q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717737776617,"user_tz":-540,"elapsed":1235,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"7612e45f-7924-431f-adef-2a4c1c3bd2fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nContinue the fibonnaci sequence.\\n\\n### Input:\\n1, 1, 2, 3, 5, 8\\n\\n### Response:\\n13<|end_of_text|>']"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":[" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"],"metadata":{"id":"CrSvZObor0lY"}},{"cell_type":"code","source":["formatted_data[-100:-1]"],"metadata":{"id":"PIpzap61YUmQ","executionInfo":{"status":"ok","timestamp":1717741649661,"user_tz":-540,"elapsed":803,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"a59dcd7b-8f92-4410-dbc7-018acf42f394","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n이등별\\n\\n### Response:\\n이등병을 막 대하지 않는다<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n하이바\\n\\n### Response:\\n방탄헬멧<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n깔바\\n\\n### Response:\\n방한 하의 내피<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꺾\\n\\n### Response:\\n계급 잔여 개월이 절반 남은 호봉<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n밀덕\\n\\n### Response:\\n밀리터리 덕후<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n골드런\\n\\n### Response:\\n노란 깔깔이와 깔바지를 맞춰 입는것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n하이바\\n\\n### Response:\\n방탄헬멧<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n깔깔이\\n\\n### Response:\\n방한복 상의 내피<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n탄알집\\n\\n### Response:\\n탄창<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뽀글이\\n\\n### Response:\\n봉지째로 익혀서 먹는 라면<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n풀창\\n\\n### Response:\\n영창 징계 최대치<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n닷지\\n\\n### Response:\\n1 1/4 군차량<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n빵실\\n\\n### Response:\\n편한 군업무<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n만창\\n\\n### Response:\\n영창 징계 최대치<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꽃신\\n\\n### Response:\\n군 복무를 기다려준 여자친구<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n가스\\n\\n### Response:\\n후임에대한 통재<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말번\\n\\n### Response:\\n마지막 근무 순번<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n땡보직\\n\\n### Response:\\n편한 보직<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n개구리\\n\\n### Response:\\n얼룩 무늬 옛 군복<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n장포대\\n\\n### Response:\\n진급 심사에서 다 떨어져서, 장성진급이 불가능한 대령<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n군대스리가\\n\\n### Response:\\n군에서 하는 축구<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뺑끼\\n\\n### Response:\\n거짓말치거나 엄살 부리다<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뱀\\n\\n### Response:\\n병장<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말출\\n\\n### Response:\\n마지막 군대 휴가<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n물광\\n\\n### Response:\\n물로낸 구두 광, 촉촉한 피부<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n깨드랑이\\n\\n### Response:\\n깨끗한 겨드랑이<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n손자\\n\\n### Response:\\n1년 낮은 후임<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n소쎄이\\n\\n### Response:\\n막 전입한 하사나 소위<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n긁다\\n\\n### Response:\\n마음의 편지로 군 부조리를 고발하는거<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말앞번\\n\\n### Response:\\n마지막 근무의 전 근무<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n스나프\\n\\n### Response:\\n대걸레<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n오대기\\n\\n### Response:\\n5분 대기조<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n짬때리다\\n\\n### Response:\\n일을 딴 사람에게 미루는 것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n닷지\\n\\n### Response:\\n1 1/4 군차량<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n사자머리\\n\\n### Response:\\n방독면을 사자머리 처럼 정리함<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n신의아들\\n\\n### Response:\\n병역면제자, 보충역, 공기업 취직자<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n가스\\n\\n### Response:\\n후임에대한 통재<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n육본\\n\\n### Response:\\n육군본부<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n야비군\\n\\n### Response:\\n예비군<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n아버지\\n\\n### Response:\\n1년 높고, 월은 똑같은 선임<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n팅커벨\\n\\n### Response:\\n큰 나방<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n에프엠\\n\\n### Response:\\n군대의 정석 지침<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n검깔\\n\\n### Response:\\n검은 깔깔이<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n깨드랑이\\n\\n### Response:\\n깨끗한 겨드랑이<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n아들\\n\\n### Response:\\n1년 낮고, 월은 똑같은 후임<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n이등별\\n\\n### Response:\\n이등병을 막 대하지 않는다<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n유도리\\n\\n### Response:\\n여유<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n골드런\\n\\n### Response:\\n노란 깔깔이와 깔바지를 맞춰 입는것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n시건\\n\\n### Response:\\n총기 등을 보관하는 것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n찐빠\\n\\n### Response:\\n하나 빼먹는 종류의 실수<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n앗세이\\n\\n### Response:\\n새 것 혹은 어린 것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n풀창\\n\\n### Response:\\n영창 징계 최대치<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말전번\\n\\n### Response:\\n마지막 근무의 전 근무<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뽀글이\\n\\n### Response:\\n봉지째로 익혀서 먹는 라면<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n군대리아\\n\\n### Response:\\n군에서 나오는 햄버거<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n짬바\\n\\n### Response:\\n연륜으로 인한 여유<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n점프\\n\\n### Response:\\n외출, 외박 위수지역을 이탈하는 것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n짬시키다\\n\\n### Response:\\n일을 미루는 것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n가라\\n\\n### Response:\\n가짜<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n진누\\n\\n### Response:\\n진급누락<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n헬보직\\n\\n### Response:\\n힘든 보직<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n군머\\n\\n### Response:\\n군대<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n탄알집\\n\\n### Response:\\n탄창<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n황금마차\\n\\n### Response:\\n격오지에  PX 물품을 파는 차량<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n만창\\n\\n### Response:\\n영창 징계 최대치<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n짬찌\\n\\n### Response:\\n군생활이 짧다는 말<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n할아버지\\n\\n### Response:\\n24개월 높은 선임<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n선탑\\n\\n### Response:\\n선임탑승자<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꽃신\\n\\n### Response:\\n군 복무를 기다려준 여자친구<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n나다싶\\n\\n### Response:\\n나다 싶으면 하자<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n군바리\\n\\n### Response:\\n군인<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말번\\n\\n### Response:\\n마지막 근무 순번<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n군대스리가\\n\\n### Response:\\n군에서 하는 축구<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꿀보직\\n\\n### Response:\\n편한 보직<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n유도리\\n\\n### Response:\\n여유<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말앞번\\n\\n### Response:\\n마지막 근무의 전 근무<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n메이커사단\\n\\n### Response:\\n유명부대<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꿀\\n\\n### Response:\\n편한 것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n망\\n\\n### Response:\\n통신네트워크<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n짬시키다\\n\\n### Response:\\n일을 미루는 것<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n이등별\\n\\n### Response:\\n이등병을 막 대하지 않는다<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n사자머리\\n\\n### Response:\\n방독면을 사자머리 처럼 정리함<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뺑이\\n\\n### Response:\\n힘든 일 할때 쓰는 말<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n검깔\\n\\n### Response:\\n검은 깔깔이<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n뺑끼\\n\\n### Response:\\n거짓말치거나 엄살 부리다<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n군대스마스\\n\\n### Response:\\n군에서 보내는 크리스마스<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n깔바\\n\\n### Response:\\n방한 하의 내피<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n꺾\\n\\n### Response:\\n계급 잔여 개월이 절반 남은 호봉<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말출\\n\\n### Response:\\n마지막 군대 휴가<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n아들\\n\\n### Response:\\n1년 낮고, 월은 똑같은 후임<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n말전번\\n\\n### Response:\\n마지막 근무의 전 근무<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n수방사\\n\\n### Response:\\n수도방위사령부<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n야비군\\n\\n### Response:\\n예비군<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n상근\\n\\n### Response:\\n상근예비역<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n신의아들\\n\\n### Response:\\n병역면제자, 보충역, 공기업 취직자<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n스나프\\n\\n### Response:\\n대걸레<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n하이바\\n\\n### Response:\\n방탄헬멧<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n오대기\\n\\n### Response:\\n5분 대기조<EOS>'},\n"," {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTranslate the following slang to a more standard form.\\n\\n### Input:\\n싸지방\\n\\n### Response:\\n사이버 지식 정보방<EOS>'}]"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Translate the following slang to a more standard form.\", # instruction\n","        \"오대기할거요\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"e2pEuRb1r2Vg","colab":{"base_uri":"https://localhost:8080/","height":571},"executionInfo":{"status":"error","timestamp":1717742501447,"user_tz":-540,"elapsed":7701,"user":{"displayName":"Playdata_GoogleColab3 Playdata_GoogleColab3","userId":"16767401162423405132"}},"outputId":"c0883645-02ba-445f-a2cb-a07f099dea24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Translate the following slang to a more standard form.\n","\n","### Input:\n","오대기할거요\n","\n","### Response:\n","오늘도 대기하는 기상관의 직원들은 오늘도 열심히 일하고 있습니다. 오늘도 기상관 직원들에게 많은 관심과 응원의 마음으로 일해주시고, 오늘도 기상관 직원들에게 많은 관심과 응원의 마음으로 일해주시고, 오늘도 기상관 직원들에게 많은 관심과 응원의 마음으로 일해주시고, 오늘도 기상관 직원들에게 많은 관심과 응원의 마음으로 일해주시고, "]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-77-2c31120b6ca9>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtext_streamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_streamer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;31m# Autocasted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1489\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   1759\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2398\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"qwen2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             outputs = fast_forward_inference(\n\u001b[0m\u001b[1;32m    796\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_rms_layernorm_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         hidden_states, present_key_value = LlamaAttention_fast_forward_inference(\n\u001b[1;32m    750\u001b[0m             \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"],"metadata":{"id":"uMuVrWbjAzhc"}},{"cell_type":"code","source":["model.save_pretrained(\"lora_model\") # Local saving\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"],"metadata":{"id":"upcOlWe7A1vc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')\n","\n","# 모델을 Google Drive에 저장\n","model.save_pretrained(\"/content/drive/MyDrive/lora_model\")\n"],"metadata":{"id":"GnhmuSMTkFr4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"],"metadata":{"id":"AEEcJ4qfC7Lp"}},{"cell_type":"code","source":["if False:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","# alpaca_prompt = You MUST copy from above!\n","\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"What is a famous tall tower in Paris?\", # instruction\n","        \"\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"],"metadata":{"id":"MKX_XKs_BNZR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713475501277,"user_tz":420,"elapsed":4957,"user":{"displayName":"Prompt Engineering","userId":"07913740242331449447"}},"outputId":"90a8de55-eff8-439c-f2db-f994033511c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is a famous tall tower in Paris?\\n\\n### Input:\\n\\n\\n### Response:\\nOne of the most famous tall towers in Paris is the Eiffel Tower. It is a wrought iron tower located on the Champ de Mars in Paris, France. It was built in 1889 as the entrance to the 1889 World's Fair, and it was designed by the French engineers Gustave Eiff\"]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."],"metadata":{"id":"QQMjaNrjsU5_"}},{"cell_type":"code","source":["if False:\n","    # I highly do NOT suggest - use Unsloth if possible\n","    from peft import AutoPeftModelForCausalLM\n","    from transformers import AutoTokenizer\n","    model = AutoPeftModelForCausalLM.from_pretrained(\n","        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        load_in_4bit = load_in_4bit,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"],"metadata":{"id":"yFfaXG0WsQuE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Saving to float16 for VLLM\n","\n","We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."],"metadata":{"id":"f422JgM9sdVT"}},{"cell_type":"code","source":["# Merge to 16bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n","\n","# Merge to 4bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n","\n","# Just LoRA adapters\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"],"metadata":{"id":"iHjt_SMYsd3P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GGUF / llama.cpp Conversion\n","To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n","\n","Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n","* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n","* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n","* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K."],"metadata":{"id":"TCv4vXHd61i7"}},{"cell_type":"code","source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")"],"metadata":{"id":"FqfebeAdT073"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html)."],"metadata":{"id":"bDp0zNpwe6U_"}},{"cell_type":"markdown","source":["And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n","\n","Some other links:\n","1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n","2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n","3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n","4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n","5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n","6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with 🤗 HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n","7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n","8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n","\n","<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n","</div>"],"metadata":{"id":"Zt9CHJqO6p30"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1mPw6P52cERr93w3CMBiJjocdTnyPiKTX","timestamp":1717979170728},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1713473529369},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c102dab5237f40bd92e8233312102ea1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18bf58832db245afbb0289f4fd2f1419","IPY_MODEL_e53621814479427e982aeefe7156eff4","IPY_MODEL_a96ab655d20f46ccb4644b8fa231e99c"],"layout":"IPY_MODEL_26e13d28bf684bfa89a22dd6f810e932"}},"18bf58832db245afbb0289f4fd2f1419":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edc1d4706df541938ddd0309160535c5","placeholder":"​","style":"IPY_MODEL_ce94a53b6df84d5692184673d1af2821","value":"Map (num_proc=2): 100%"}},"e53621814479427e982aeefe7156eff4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1db5248c3ceb4803a8b64804ffa1dfa2","max":50552,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d9d7b02ce004076b5a314877c8941f1","value":50552}},"a96ab655d20f46ccb4644b8fa231e99c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e4e0fceb42d47abb64d14b407aede7b","placeholder":"​","style":"IPY_MODEL_d66ca205de864ef7a6c1d73b1cf3b3a9","value":" 50552/50552 [00:08&lt;00:00, 4037.37 examples/s]"}},"26e13d28bf684bfa89a22dd6f810e932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edc1d4706df541938ddd0309160535c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce94a53b6df84d5692184673d1af2821":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1db5248c3ceb4803a8b64804ffa1dfa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d9d7b02ce004076b5a314877c8941f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e4e0fceb42d47abb64d14b407aede7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d66ca205de864ef7a6c1d73b1cf3b3a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}